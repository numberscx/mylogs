# the solutions of The Great Promotion

## 0 introduction

大促是指的是一段时间内、某些时刻，商品的访问量、下单量到达一个高峰。

对于商户系统，面临的挑战是保证商品库存的实时性、可靠性；

对于支付系统来说，面临的挑战则是支付工具的可用性、可靠性。

最近刚经历了在支付链路上大促的优化，本文将对软件实现上的优化方案相关内容进行整理，并对背后涉及的技术原理进行基本的拓展。



## 1 target

首先说明大促时，支付链路的性能优化需要做些什么呢？

下面先简单说明基本的支付链路图：

![11](.\pic\trade.png)

![trade](./pic/trade.png

上图是支付链路的简图，在大部分电商平台，对用户可见的只有商品购买的页面；而在电商平台的视角，在支付链路上，分为了已下几个部分：

1.收银台渲染。目前大部分电商平台都支持多种资产，不仅包含自身资产（例如平台余额、平台分期账户），还包含多种外部资产（例如支付宝支付、微信支付、信用卡支付等）。

2.用户支付及支付结果处理。对内部资产和外部资产的扣款、支付结果，需要做统一封装，保证用户使用不同支付工具获得相等体验。

3.商家结算。在用户支付成功后需要将钱结算给商家。

4.会计清核算等等。。

## 2 problems and reasons

在支付链路的大促需求下，存在一些难点、痛点：

### 2.1、支付咨询的耗时问题

该问题的原因是若存在多个资产，若同步咨询，则会导致用户收银台渲染速度非常慢；而若采用并发咨询，同样存在因某个资产咨询结果太慢影响渲染。

这里的关键问题是，保证一定时间内把能咨询到的资产显示给用户，若部分资产咨询速度过慢，则直接抛弃不等待。

### 2.2、高并发下网络异常引起的资损风险

资损问题是支付领域非常关注的问题，相比之下，偶尔的不可用反而是能接受的，但资损问题，是万万不能接受的。这里面的资损问题，最严重的自然是对客资损、对商家资损。

资损问题通常是不合理的单据处理、不合理的资金流动引起的，一般的处理方式为：在面临预期外的状态时，将单子挂起，后续通过核对以及日志报警提醒客服、研发人员，手动处理异常单子。

### 2.3、机器性能在压测时总是表现不佳

体现在cpu占用率压不上去，用户请求耗时会突然居高不下。

压测是模拟大促的有效方式，压测常见的cpu占用率问题，体现的是机器运行资源配置不合理，例如线程池配置不合理、jvm参数不合理，而用户请求的耗时，除了下游因素外，一般都与数据库执行效率、重复不必要的调用有关，当然，频繁的gc也会引起用户请求耗时的增加。

## 3 solutions

针对以上问题，总结出下面方案：

### 3.1、支付咨询的耗时问题

该问题实质上要解决的问题是实现限制时间的并发查询。

**方案一** 限制rpc的超时时间

对于微服务架构，每个资产组可能都由一个rpc接口来返回结果，那么只要控制改接口的超时时间，就可以保证获取结果的时间是确定的。

**方案二** 使用并发包中的completeFuture来控制时间

不提了，简单的实现，需要注意的是，completeFuture的异常堆栈并非真实堆栈，导致排查问题时无法排查，需要稍微处理下（debug看下真实堆栈在哪就行）。

### 3.2、网络异常引起的资损风险

作为新手，能非常轻松的造成大量资损问题。我本人也曾因考虑不周，给程序设计埋下资损隐患的坑。从客观规律看，经验是最可靠的，只要资损问题出的够多，那再设计出资损缺陷的几率就会小；但是对领导就不能这么说。

虽进入支付行业还不到两年，但也看到过不少的资损问题案例，例如：

1.幂等性做的不够好的支付结果处理----处理用户支付结果时，采用的方案是，若推进交易失败，则走支付撤销给用户退钱。然而连续两次支付结果通知，会造成一次退钱、一次推进成功的问题。这里的解决方式是使用更完善的状态机严格划分订单状态，一旦确定了成功、失败，那必然不可走其他流程。

2.薛定谔的用户退款（这用户到底是收到钱了还是没收到钱呢？）----处理退款时，调用同步接口进行退款，拿到返回后更新退款单据。由于没有消息补偿，这里一旦出现超时问题，单据就无法更新，会出现实际退成功了，但是订单显示还没退成功，对于不太合理的链路设计，这里会有退两次的风险。

临时兜底方案是先做状态更新操作，然后去执行退款，后续通过离线数据核对来发现不一致的问题。当然，最佳方案自然是增加异步消息通知。

。。。

解决方案并不难，难的是发现问题本身。

作为研发人员，只有小心、谨慎的面对任何一个设计资金流的流程，单靠测试来覆盖边界case，意义并不大。

### 3.3、提升机器在压测时的表现

这个标题看着像是在做一件无意义的事，“提高压测的表现”看上去像是展示给leader的PPT，当然，真正实践过的人绝不会这么认为。

在压测时，我们发现两个方面会大大影响机器的运行效率：

1.线程池的设计。压测一般针对热点链路，对于这部分业务，线程池的使用不可避免。优化方式包含以下部分：

​	a.线程池监控，没有线程池的监控，优化就是抓瞎，无从谈起，虽然可以从tps、单次请求耗时算出线程池大小，但实际情况往往和计算有出入。

​	b.线程池参数调优。一般在实际中使用的线程池一般为java并发包中的ThreadPoolExecutor，该线程池的特点是，初始会创建n个核心线程，在系统面临核心线程数不够的情况下，会先往等待队列中塞，塞满了才会创建新线程，在这个过程中，会造成类似于饥饿（某请求长时间等待）的结果，因此，核心线程数、最大线程数的设置非常重要，需要考虑到日常tps和峰值tps。

​	c.大促预热。预热是非常简单粗暴但有效的方式，在线程池上的作用是，可以通过把等待队列打满，将线程池规模扩大，从而更好的迎接大促，至于预热的时间，则和线程池的线程生存时间相关--起码保证在大促前，这部分非线程不被杀掉。

2.JVM的调优。大促时，重点考虑的问题是减少系统不可用时间，自顶向下看，就是避免进程长时间进入stop the world的状态。因此，我们将java应用的垃圾收集器从CMS升级成了G1，G1的一大亮点就是可以控制垃圾回收的时长。当然，值得一提的是，G1适合内存8G及以上的机器，由于其分区的特殊性，卡表较为庞大，不适合小内存服务器。

​	a.G1的特点。G1的最大特点即为用户可以控制垃圾回收的时间，在软件工程中，相较于可用性，更担心的是不可控制的可用性，例如某机器平时不怎么GC，看起来很懂垃圾清理，一到大促就开始掉链子，全范围的STW，持续3-4秒的垃圾清理；与之相比，大促时频繁垃圾清理，但是每次就清理那么100ms，显然可接受的多。

​	b.G1的jvm 参数设计。

​	`Xms 堆内存的最小Heap值` `Xmx 堆内存的最大heap值` 两者一般控制成一样，防止内存抖动，该值可以设置为full gc后老年代大小的3-4倍。

​	`MaxGCPauseMills`默认为200ms。

​	`Xmn`新生代大小，一般使用默认值。在5%~60%的Heap范围内浮动。

​	`G1ReservePercent`=10.由于G1在young GC失败（promotion failure）后，会导致失败的young GC区变成old region，因此需要保留一部分备用。

​	`G1LogLevel`调整log level可以提高性能。

